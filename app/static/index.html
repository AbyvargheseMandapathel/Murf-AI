<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0"/>
  <title>30 Days of AI Voice Agents</title>
  <script src="https://cdn.tailwindcss.com"></script>
  <script>
    tailwind.config = {
      theme: {
        extend: {
          colors: {
            primary: '#121212',
            secondary: '#1E1E1E',
            accent: '#00FF88',
          }
        }
      }
    }
  </script>
</head>
<body class="bg-primary text-gray-100 min-h-screen flex flex-col items-center">
  <div class="w-full max-w-3xl mx-auto p-6 md:p-8 my-8 bg-secondary rounded-xl shadow-2xl">

    <!-- Header -->
    <header class="text-center mb-8 pb-6 border-b border-accent">
      <h1 class="text-accent text-3xl md:text-4xl font-bold mb-2">30 Days of AI Voice Agents</h1>
      <p class="text-gray-400">Presented by <span class="text-accent font-bold">Murf.ai</span></p>
      <p class="text-gray-400 mt-2">Day 9: Full Non-Streaming Pipeline</p>
    </header>

    <!-- TTS -->
    <section class="mb-10">
      <h2 class="text-accent text-xl font-semibold mb-4">Text-to-Speech</h2>
      <form id="tts-form" class="flex flex-col gap-4">
        <textarea id="tts-input" rows="4" class="w-full p-4 bg-gray-700 border-2 border-gray-600 rounded-lg text-gray-100 focus:outline-none focus:border-accent transition" placeholder="Type text here..." required></textarea>
        <button type="submit" class="bg-accent text-primary font-bold py-3 px-6 rounded-lg hover:bg-green-400 transition">Generate Audio</button>
      </form>
      <div id="audio-container" class="mt-6 hidden">
        <audio id="tts-audio" controls class="w-full rounded-lg"></audio>
        <button id="download-btn" class="mt-2 text-accent hover:text-green-300">Download Audio</button>
      </div>
    </section>

    <!-- LLM Voice Agent -->
    <section>
      <h2 class="text-accent text-xl font-bold mb-4">LLM Voice Agent (Speech → LLM → Murf Voice)</h2>
      <div class="flex gap-2">
        <button id="start-record-btn" class="bg-accent text-primary font-bold py-2 px-4 rounded-lg hover:bg-green-400">Start Recording</button>
        <button id="stop-record-btn" class="bg-gray-600 text-gray-200 font-semibold py-2 px-4 rounded-lg hover:bg-gray-500" disabled>Stop</button>
      </div>
      <p id="record-status" class="mt-3 text-gray-300">Idle</p>
      <pre id="transcription-result" class="mt-4 text-accent font-semibold whitespace-pre-wrap"></pre>
      <audio id="echo-audio" controls class="w-full rounded-lg mt-3"></audio>
    </section>

  </div>

  <script>
    // ==== TTS ====
    document.getElementById('tts-form').addEventListener('submit', async (e) => {
      e.preventDefault();
      const text = document.getElementById('tts-input').value;
      const response = await fetch('/generate-audio/', {
        method: 'POST',
        headers: { 'Content-Type': 'application/json' },
        body: JSON.stringify({ text })
      });
      const data = await response.json();
      document.getElementById('tts-audio').src = data.audio_url;
      document.getElementById('audio-container').classList.remove('hidden');
      document.getElementById('download-btn').onclick = () => {
        const a = document.createElement('a');
        a.href = data.audio_url;
        a.download = `tts-${Date.now()}.mp3`;
        a.click();
      };
    });

    // ==== LLM Voice Agent ====
    let llmRecorder, llmChunks = [];
    document.getElementById('start-record-btn').onclick = async () => {
      const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
      llmRecorder = new MediaRecorder(stream);
      llmChunks = [];

      llmRecorder.ondataavailable = e => llmChunks.push(e.data);

      llmRecorder.onstop = async () => {
        const blob = new Blob(llmChunks, { type: 'audio/webm' });
        const formData = new FormData();
        formData.append('file', blob, 'speech.webm');

        document.getElementById('record-status').textContent = 'Processing...';
        document.getElementById('transcription-result').textContent = '';

        try {
          const resp = await fetch('/llm/query', { method: 'POST', body: formData });
          const data = await resp.json();

          if (resp.ok) {
            // Audio playback
            if (data.audio_url) {
              document.getElementById('echo-audio').src = data.audio_url;
            } else if (data.audio_urls) {
              document.getElementById('echo-audio').src = data.audio_urls[0];
            }

            // Show both user speech & LLM reply
            document.getElementById('transcription-result').textContent =
              `You said: "${data.transcript}"\nLLM: "${data.llm_text}"`;

            document.getElementById('record-status').textContent = 'Done';
          } else {
            document.getElementById('record-status').textContent = 'Error';
            document.getElementById('transcription-result').textContent =
              `Failed: ${data.detail || 'Unknown error'}`;
          }
        } catch (err) {
          document.getElementById('record-status').textContent = 'Error';
          document.getElementById('transcription-result').textContent =
            `Failed: ${err.message}`;
        }
      };

      llmRecorder.start();
      document.getElementById('record-status').textContent = 'Recording...';
      document.getElementById('stop-record-btn').disabled = false;
    };

    document.getElementById('stop-record-btn').onclick = () => {
      llmRecorder.stop();
      document.getElementById('stop-record-btn').disabled = true;
    };
  </script>
</body>
</html>
