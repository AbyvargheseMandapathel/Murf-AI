<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0"/>
  <title>AI Voice Agent</title>
  <script src="https://cdn.tailwindcss.com"></script>
  <script>
    tailwind.config = {
      theme: {
        extend: {
          colors: {
            primary: '#0f172a',
            secondary: '#1e293b',
            accent: '#22d3ee',
            'accent-dark': '#0ea5e9',
          },
          animation: {
            'pulse-slow': 'pulse 3s cubic-bezier(0.4, 0, 0.6, 1) infinite',
            'ping-slow': 'ping 1.5s cubic-bezier(0, 0, 0.2, 1) infinite',
          }
        }
      }
    }
  </script>
  <style>
    @keyframes wave {
      0% { transform: scale(1); opacity: 1; }
      50% { transform: scale(1.1); opacity: 0.7; }
      100% { transform: scale(1); opacity: 1; }
    }
    .animate-wave {
      animation: wave 1.5s ease-in-out infinite;
    }
  </style>
</head>
<body class="bg-primary text-gray-100 min-h-screen flex flex-col items-center justify-center p-4">

  <div class="w-full max-w-2xl bg-secondary rounded-xl shadow-2xl p-6 flex flex-col h-[85vh]">
    <header class="text-center mb-6">
      <h1 class="text-accent text-3xl font-bold">Voice Assistant</h1>
      <p class="text-gray-400 mt-1">Talk naturally with your AI assistant</p>
    </header>

    <!-- Chat History -->
    <div id="chat-box" class="flex-1 bg-gray-800/50 rounded-xl p-4 overflow-y-auto space-y-4 mb-6">
      <div class="text-center text-gray-400 py-8">
        <p>Press the microphone button to start talking</p>
      </div>
    </div>

    <!-- Controls -->
    <div class="flex flex-col items-center">
      <button id="record-btn" class="w-16 h-16 rounded-full bg-accent hover:bg-accent-dark text-primary flex items-center justify-center text-2xl shadow-lg transition-all duration-300 transform hover:scale-105 focus:outline-none focus:ring-2 focus:ring-accent focus:ring-opacity-50">
        <svg id="mic-icon" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round">
          <path d="M12 1a3 3 0 0 0-3 3v8a3 3 0 0 0 6 0V4a3 3 0 0 0-3-3z"></path>
          <path d="M19 10v2a7 7 0 0 1-14 0v-2"></path>
          <line x1="12" y1="19" x2="12" y2="23"></line>
          <line x1="8" y1="23" x2="16" y2="23"></line>
        </svg>
      </button>
      <p id="status-text" class="mt-3 text-sm text-gray-400">Ready</p>
    </div>
  </div>

  <audio id="bot-audio" class="hidden"></audio>

  <script>
    // Generate or retrieve session ID
    function getOrCreateSessionId() {
      let sessionId = localStorage.getItem('voiceAgentSessionId');
      if (!sessionId) {
        sessionId = crypto.randomUUID();
        localStorage.setItem('voiceAgentSessionId', sessionId);
      }
      return sessionId;
    }
    const SESSION_ID = getOrCreateSessionId();

    // DOM elements
    const recordBtn = document.getElementById('record-btn');
    const statusText = document.getElementById('status-text');
    const chatBox = document.getElementById('chat-box');
    const botAudio = document.getElementById('bot-audio');
    const micIcon = document.getElementById('mic-icon');

    // State variables
    let recorder, chunks = [], isRecording = false;

    // Add message to chat
    function addMessage(role, text) {
      // Clear initial placeholder if it exists
      if (chatBox.children.length === 1 && chatBox.children[0].classList.contains('text-center')) {
        chatBox.innerHTML = '';
      }

      const msgDiv = document.createElement('div');
      msgDiv.className = `flex ${role === 'user' ? 'justify-end' : 'justify-start'}`;
      
      const bubble = document.createElement('div');
      bubble.className = role === 'user' 
        ? 'bg-accent text-primary px-4 py-3 rounded-2xl rounded-br-none max-w-[80%]'
        : 'bg-gray-700 text-gray-200 px-4 py-3 rounded-2xl rounded-bl-none max-w-[80%]';
      
      bubble.textContent = text;
      msgDiv.appendChild(bubble);
      chatBox.appendChild(msgDiv);
      chatBox.scrollTop = chatBox.scrollHeight;
    }

    // Start recording
    async function startRecording() {
      try {
        const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
        recorder = new MediaRecorder(stream);
        chunks = [];
        
        recorder.ondataavailable = e => chunks.push(e.data);
        recorder.onstop = handleRecordingStop;
        recorder.start(100); // Collect data every 100ms
        
        isRecording = true;
        recordBtn.classList.add('animate-wave', 'bg-red-500', 'hover:bg-red-600');
        micIcon.innerHTML = `<path d="M12 1a3 3 0 0 0-3 3v8a3 3 0 0 0 6 0V4a3 3 0 0 0-3-3z"></path><path d="M19 10v2a7 7 0 0 1-14 0v-2"></path><line x1="12" y1="19" x2="12" y2="23"></line><line x1="8" y1="23" x2="16" y2="23"></line>`;
        statusText.textContent = "Listening...";
        
      } catch (error) {
        console.error('Recording error:', error);
        statusText.textContent = "Error accessing microphone";
        setTimeout(() => statusText.textContent = "Ready", 3000);
      }
    }

    // Stop recording
    function stopRecording() {
      if (!recorder || !isRecording) return;
      
      isRecording = false;
      recorder.stop();
      recordBtn.classList.remove('animate-wave', 'bg-red-500', 'hover:bg-red-600');
      recordBtn.classList.add('bg-gray-500', 'cursor-not-allowed');
      micIcon.innerHTML = `<path d="M1 1l22 22"></path><path d="M9 9v3a3 3 0 0 0 5.12 2.12M15 9.34V4a3 3 0 0 0-5.94-.6"></path><path d="M17 16.95A7 7 0 0 1 5 12v-2m14 0v2a7 7 0 0 1-.11 1.23"></path><line x1="12" y1="19" x2="12" y2="23"></line><line x1="8" y1="23" x2="16" y2="23"></line>`;
      statusText.textContent = "Processing...";
    }

    // Handle recording completion
    async function handleRecordingStop() {
    try {
        const blob = new Blob(chunks, { type: 'audio/webm' });
        addMessage('user', "ðŸŽ¤ Processing your voice message...");

        const formData = new FormData();
        formData.append('file', blob, 'voice-input.webm');

        const response = await fetch(`/agent/chat/${SESSION_ID}`, {
            method: 'POST',
            body: formData
        });

        if (!response.ok) {
            const errorData = await response.json();
            throw new Error(errorData.detail || 'Request failed');
        }

        const data = await response.json();
        
        // Update the user message with actual transcription
        const lastUserMessage = chatBox.querySelector('.justify-end:last-child');
        if (lastUserMessage && data.transcript) {
            lastUserMessage.querySelector('div').textContent = data.transcript;
        }

        if (data.llm_text) {
            addMessage('bot', data.llm_text);
        }

        // Play bot response
        if (data.audio_url) {
            botAudio.src = data.audio_url;
            botAudio.play();
            statusText.textContent = "Assistant is speaking...";
            botAudio.onended = resetUI;
        } else {
            resetUI();
        }

    } catch (error) {
        console.error('Error:', error);
        statusText.textContent = "Error: " + error.message;
        addMessage('bot', "Sorry, I couldn't process that. Please try again.");
        resetUI();
    }
}

    // Reset UI to ready state
    function resetUI() {
      recordBtn.classList.remove('bg-gray-500', 'cursor-not-allowed');
      recordBtn.classList.add('bg-accent', 'hover:bg-accent-dark');
      micIcon.innerHTML = `<path d="M12 1a3 3 0 0 0-3 3v8a3 3 0 0 0 6 0V4a3 3 0 0 0-3-3z"></path><path d="M19 10v2a7 7 0 0 1-14 0v-2"></path><line x1="12" y1="19" x2="12" y2="23"></line><line x1="8" y1="23" x2="16" y2="23"></line>`;
      statusText.textContent = "Ready";
    }

    // Toggle recording
    recordBtn.addEventListener('click', () => {
      if (isRecording) {
        stopRecording();
      } else {
        startRecording();
      }
    });

    // Initialize
    resetUI();
  </script>
</body>
</html>